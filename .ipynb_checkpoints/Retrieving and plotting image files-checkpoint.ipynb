{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import joblib\n",
    "#import re\n",
    "import glob\n",
    "import time\n",
    "import rasterio\n",
    "import requests\n",
    "#import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "from rasterio.plot import show\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Users/Yash/Dev/CRISMIS GSoC Project/try\"\n",
    "base_url = \"https://pdsimage2.wr.usgs.gov/archive/mess-e_v_h-mdis-2-edr-rawdata-v1.0/MSGRMDS_1001/DATA/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently retrieval has been executed on the basis of scraping the website for all the data, and making it available locally. However, it can be modified to just search for a particular image online and download that only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize():\n",
    "    '''\n",
    "    '''\n",
    "    try:\n",
    "        os.chdir(base_dir)\n",
    "        #print(os.getcwd())\n",
    "    except:\n",
    "        print(\"Error in changing directory\")\n",
    "        \n",
    "    data_dir = base_dir + '/retrieved_data/'\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        try:\n",
    "            os.mkdir(\"./retrieved_data/\")\n",
    "            print(\"Data Directory initialized\")\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        print(\"Directory \\\"retrieved_data\\\" already present !\")\n",
    "            \n",
    "    try:\n",
    "        os.chdir(data_dir)\n",
    "        print(os.getcwd())\n",
    "    except:\n",
    "        print(\"Error in changing directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloader(url, path):\n",
    "    '''\n",
    "    Download helper function \n",
    "    \n",
    "    Keyword arguments:\n",
    "    url     -- the url to the file to download\n",
    "    path    -- full path to where to save the file\n",
    "    \n",
    "    '''\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        time.sleep(5)\n",
    "        response = requests.get(url)\n",
    "    \n",
    "    if response:\n",
    "        open(path, 'wb').write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever(doy, *varg):  \n",
    "    day_url = base_url + doy\n",
    "    response = requests.get(day_url)\n",
    "    data = response.text\n",
    "    soup =  bs(data, 'html.parser')\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)\n",
    "    work_dir = os.path.join(base_dir, 'retrieved_data', doy)\n",
    "    print(work_dir)\n",
    "    \n",
    "    if not os.path.exists(work_dir):\n",
    "        try:\n",
    "            os.mkdir(work_dir)\n",
    "            print(\"Work Directory initialized\")\n",
    "        except:\n",
    "            print(\"Directory \\\"\" + doy + \"\\\" already present !\")  \n",
    "            \n",
    "    try:\n",
    "        os.chdir(work_dir)\n",
    "        cwd = os.getcwd()\n",
    "        print(cwd)\n",
    "    except:\n",
    "        print(\"Error in changing directory\")\n",
    "    \n",
    "    if not varg:\n",
    "        for href in soup.find_all('a'):\n",
    "            link = href.get('href')\n",
    "            if(link[0] not in ('?','/')):\n",
    "                req_url = day_url + link\n",
    "                print(link)\n",
    "                print(req_url)\n",
    "                path = work_dir + link\n",
    "                downloader(req_url, path)\n",
    "    else:\n",
    "        for arg in varg:\n",
    "            req_url = day_url + arg\n",
    "            print(arg)\n",
    "            print(req_url)\n",
    "            path = work_dir + arg\n",
    "            downloader(req_url, path)\n",
    "                \n",
    "    os.chdir('../')\n",
    "    cwd = os.getcwd()\n",
    "    print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all():\n",
    "    response = requests.get(base_url)\n",
    "    data = response.text\n",
    "    soup =  bs(data, 'html.parser')\n",
    "    \n",
    "    for href in tqdm(soup.find_all('a'), \"Getting Links\"):\n",
    "        link = href.get('href')\n",
    "        if(link[0] not in ('?','/')):\n",
    "            print(link)\n",
    "            retriever(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2011\n",
    "day = 207\n",
    "img1 = 'EW0220137668G.IMG'\n",
    "doy = str(year) + \"_\" + str(day) + \"/\"\n",
    "doy\n",
    "retriever(doy, img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in glob.glob(base_dir + \"/retrieved_data/**/*.IMG\", recursive=True)]\n",
    "for f in files:\n",
    "    if f.find(img1) != -1:\n",
    "        target = f\n",
    "        break\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rasterio.open(target)\n",
    "show(dataset, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2014\n",
    "day = 215\n",
    "img2 = 'EN1049375684M.IMG'\n",
    "doy = str(year) + \"_\" + str(day) + \"/\"\n",
    "doy\n",
    "retriever(doy, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in glob.glob(base_dir + \"/retrieved_data/**/*.IMG\", recursive=True)]\n",
    "for f in files:\n",
    "    if f.find(img2) != -1:\n",
    "        target = f\n",
    "        break\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = rasterio.open(target)\n",
    "show(dataset, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
